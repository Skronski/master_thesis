{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d53e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6852f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'D:/Informatyka i ekonometria/praca magisterska/expresso_churn/output/'\n",
    "path = 'D:/Informatyka i ekonometria/praca magisterska/expresso_churn/input/'\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bb26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_variables = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT',\n",
    "                     'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
    "                     'ZONE1', 'ZONE2', 'REGULARITY', 'FREQ_TOP_PACK']\n",
    "\n",
    "categorical_variables = ['REGION', 'TOP_PACK', 'TENURE', 'MRG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d3b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    for column in df.select_dtypes(include=[np.number]).columns: #replace numeric NaN with mean\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "    for column in df.select_dtypes(include=[\"object\"]).columns: #replace categories with most popular values \n",
    "        df[column].fillna(df[column].mode().iloc[0], inplace=True)\n",
    "\n",
    "    # Check duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Drop the 'user_id' column, if it exists\n",
    "    df = df.drop(['user_id'], axis=1, errors='ignore')\n",
    "\n",
    "    #Label encoding\n",
    "    #le = LabelEncoder()\n",
    "    #df.MRG = le.fit_transform(df.MRG)\n",
    "    #df.TENURE = le.fit_transform(df.TENURE)\n",
    "    #df.REGION = le.fit_transform(df.REGION)\n",
    "    #df.TOP_PACK = le.fit_transform(df.TOP_PACK)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2999c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df, columns=categorical_variables, drop_first = True)\n",
    "dummy_names = list(dummy_df.columns)\n",
    "dummy_names.remove('CHURN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f51080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4996d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_third_quartile(column):\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - column.quantile(0.25)\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return column.apply(lambda x: q3 if x > upper_bound else x)\n",
    "\n",
    "for col in numeric_variables:\n",
    "    df[col] = replace_outliers_with_third_quartile(df[col])\n",
    "    \n",
    "def replace_outliers_with_first_quartile(column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    iqr = column.quantile(0.75) - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    return column.apply(lambda x: q1 if x < lower_bound else x)\n",
    "\n",
    "for col in numeric_variables:\n",
    "    df[col] = replace_outliers_with_first_quartile(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8c9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['CHURN']\n",
    "X = df.drop(['CHURN'], axis=1, errors='ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=2137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b9e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, KBinsDiscretizer\n",
    "\n",
    "def apply_all_transformations(X_train, X_test, X_train_dummies, X_test_dummies):\n",
    "    '''\n",
    "    input df: X_train, X_test\n",
    "    making transformation: standarization, scaling, log transformation etc. \n",
    "    return transformed train and test set\n",
    "    '''\n",
    "\n",
    "    # Min-Max Scaling\n",
    "   # min_max_scaler = MinMaxScaler()\n",
    "   # X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "   # X_test_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "    # Log Transformation\n",
    "    X_train_log = np.log1p(X_train)\n",
    "    X_test_log = np.log1p(X_test)\n",
    "\n",
    "    # sqrt Transformation\n",
    "    X_train_sqrt = np.sqrt(X_train)\n",
    "    X_test_sqrt = np.sqrt(X_test)\n",
    "    \n",
    "    # pow Transformation\n",
    "    X_train_pow = np.power(X_train,2)\n",
    "    X_test_pow = np.power(X_test, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Power Transformation (using Yeo-Johnson to handle non-positive data)\n",
    "    power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "    X_train_power = power_transformer.fit_transform(X_train)\n",
    "    X_test_power = power_transformer.transform(X_test)\n",
    "\n",
    "    # Concatenate all transformed features along columns with appropriate suffixes\n",
    "    X_train_combined = np.hstack([\n",
    "       # X_train_scaled,\n",
    "        X_train_log,\n",
    "        X_train_power,\n",
    "        X_train_sqrt,\n",
    "        X_train_pow\n",
    "    ])\n",
    "    X_test_combined = np.hstack([\n",
    "       # X_test_scaled,\n",
    "        X_test_log,\n",
    "        X_test_power,\n",
    "        X_test_sqrt,\n",
    "        X_test_pow\n",
    "    ])\n",
    "\n",
    "    # Create column names with appropriate suffixes\n",
    "    col_names = []\n",
    "    for col in X_train.columns:\n",
    "        col_names.extend([\n",
    "          #  f\"{col}_scaled\",\n",
    "            f\"{col}_log\",\n",
    "            f\"{col}_power\",\n",
    "            f'{col}_sqrt',\n",
    "            f'{col}_pow_2'\n",
    "        ])\n",
    "    \n",
    "    col_names = col_names + list(X_train_dummies.columns)\n",
    "    X_train_combined_with_dummies = np.hstack([\n",
    "        X_train_combined,\n",
    "        X_train_dummies\n",
    "    ])\n",
    "    X_test_combined_with_dummies = np.hstack([\n",
    "        X_test_combined,\n",
    "        X_test_dummies\n",
    "    ])\n",
    "    # Convert back to DataFrames with new column names\n",
    "    X_train_combined_df = pd.DataFrame(X_train_combined_with_dummies, columns=col_names)\n",
    "    X_test_combined_df = pd.DataFrame(X_test_combined_with_dummies, columns=col_names)\n",
    "\n",
    "    return X_train_combined_df, X_test_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bda8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = apply_all_transformations(X_train[numeric_variables], X_test[numeric_variables], X_train[dummy_names], X_test[dummy_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff281f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_std, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_std, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743cd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train_after_transformations.csv', index = False) \n",
    "X_test.to_csv('X_test_after_transformations.csv', index = False) \n",
    "y_train.to_csv('y_train.csv', index = False)\n",
    "y_test.to_csv('y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64364a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
